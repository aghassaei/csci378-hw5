{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41df66f0-9815-4dce-bdc7-41896a98a43a",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Description\n",
    "\n",
    "In this homework, you'll tune some hyperparameters to try to improve the performance of a network. This will involve setting up a convolutional network for the CIFAR-10 dataset, setting up TensorBoard for logging, and then experimenting. I am _not_ going to be setting specific accuracy targets for different grades because there is too much randomness in the training process. Moreover, achieving high accuracy is easier if you have access to a lot of computational resources, so there are some equity issues with just grading by final model performance.\n",
    "\n",
    "Instead, I'm going to ask you to explain your tuning _process_. That is, for each experiment you run (each set of hyperparameters you try), explain why you ran that experiment and what happened. Based on your observations, what changes did you make for the next run? As long as you have explained your reasoning and it corresponds to the principles we've talked about in class, you'll do fine. Be sure to set up your logging in a way that indicates the hyperparameter values used for each run.\n",
    "\n",
    "**IMPORTANT: Please zip up and submit your TensorBoard log files with your homework. That will help me to see what you were looking at as you went through your tuning process.**\n",
    "\n",
    "I'm also deliberately giving you no starter code for this homework. I understand that a lot of it will just be copy-paste from past classes/labs/homeworks but I still think there is some value in going from a blank document to a complete program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42258a4e-c217-46e7-a969-30635cb8d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineRenderer.figure_format = 'retina'\n",
    "\n",
    "\n",
    "import torch.utils.tensorboard as tb\n",
    "import datetime\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec783b1",
   "metadata": {},
   "source": [
    "### Setting up the data and tensorboard\n",
    "\n",
    "Make directories to save the models and logs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623ed617",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d446ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Setting the transform so that the images are put in the right format\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ConvertImageDtype(),\n",
    "])\n",
    "\n",
    "# Load data\n",
    "cifar = torchvision.datasets.CIFAR10(\"../../data/torch/cifar\", download=True, transform=transform)\n",
    "\n",
    "# Set the training size to 80% of the total data\n",
    "train_size = int(0.8 * len(cifar))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, valid_data = torch.utils.data.random_split(cifar, [train_size, len(cifar) - train_size])\n",
    "\n",
    "# These are the classes within the dataset\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f6298",
   "metadata": {},
   "source": [
    "Get the necessary constants and define normalization for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "normalize = transforms.Normalize(cifar_mean, cifar_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41273b69",
   "metadata": {},
   "source": [
    "### setting up the CNN\n",
    "\n",
    "\n",
    "I want to set up my CNN such that I can change the convolutions in each run, partially because that will make a difference and partially because i don't fully understand the math. I will always end with flattening and a linear layer, but I will need to change the parameters for `nn.Linear` depending on the previous convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0b6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, convolutions = torch.nn.ModuleList( \n",
    "                 nn.Conv2d(3, 8, 3, padding=3), \n",
    "                  nn.Conv2d(8, 16, 3, groups=2, padding=1, stride=2), \n",
    "                  nn.Conv2d(16, 32, 3, stride=2)), \n",
    "                  activation = nn.ReLU):\n",
    "        super().__init__()\n",
    "        # have some checker function to make sure the math is right \n",
    "\n",
    "        # Dynamically create attributes for each convolution\n",
    "        self.convolutions = convolutions\n",
    "\n",
    "        self.activation = activation()\n",
    "\n",
    "        self.num_convolutions\n",
    "\n",
    "        # for i in range(len(convolutions)):\n",
    "        #     setattr(CNN, 'conv'+str(i), conv)\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fix linear inputs so it's dynamic\n",
    "        self.linear =  nn.Linear(32*8*8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for i in range(self.num_convolutions):\n",
    "            conv = self.convolutions[i]\n",
    "            x = conv(x)\n",
    "            if i == self.num_convolutions -1: break\n",
    "            x = activation(x)\n",
    "\n",
    "        flattened = self.flatten(h5)\n",
    "        return self.linear(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd863b20",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6dae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run, convolutions=torch.nn.ModuleList(nn.Conv2d(3, 8, 3, padding=3), nn.Conv2d(8, 16, 3, groups=2, padding=1, stride=2), nn.Conv2d(16, 32, 3, stride=2)),lr=1e-3,epochs=10,batch_size=64,reg=1e-5,activation=nn.ReLU, use_augmentation=False,aug_params=[], device = 'mps'):\n",
    "    start = time.time()\n",
    "    data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    if use_augmentation:\n",
    "        augments = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(aug_params['flip_prob']),\n",
    "            transforms.RandomGrayscale(aug_params['grayscale_prob']),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=(aug_params['bright_min'], aug_params['bright_max']),\n",
    "                contrast=0,\n",
    "                saturation=0,\n",
    "                hue=0),\n",
    "            transforms.RandomCrop(\n",
    "                size=32,\n",
    "                padding=aug_params['shift_size'],\n",
    "                fill=cifar_mean)\n",
    "        ])\n",
    "\n",
    "    model = CNN(convolutions).to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    opt = optim.SGC(model.parameters(), momentum=0.9, lr=lr, weight_decay=reg)\n",
    "\n",
    "    # Naming the training runs\n",
    "    name += str(run) + '--' # Run number\n",
    "    name += \":\".join(map(str, convolutions))\n",
    "    name += '-lr-' + str(lr) + '-bs-' + str(batch_size) + '-epochs-' + str(epochs) + '-reg-' + str(reg)\n",
    "    logger = tb.SummaryWriter(os.path.join(\"logs/\", name))\n",
    "    global_step = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98564aa4",
   "metadata": {},
   "source": [
    "## Training and tuning\n",
    "\n",
    "\n",
    "will be a loop\n",
    "\n",
    "First, we want to make sure that we don this on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "else:\n",
    "    decive = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0992c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up first training loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
