{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41df66f0-9815-4dce-bdc7-41896a98a43a",
   "metadata": {},
   "source": [
    "# Parameter tuning\n",
    "\n",
    "**IMPORTANT: Please zip up and submit your TensorBoard log files with your homework. That will help me to see what you were looking at as you went through your tuning process.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42258a4e-c217-46e7-a969-30635cb8d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineRenderer.figure_format = 'retina'\n",
    "\n",
    "\n",
    "import torch.utils.tensorboard as tb\n",
    "import datetime\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec783b1",
   "metadata": {},
   "source": [
    "### Setting up the data and tensorboard\n",
    "\n",
    "Make directories to save the models and logs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "623ed617",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d446ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Setting the transform so that the images are put in the right format\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ConvertImageDtype(),\n",
    "])\n",
    "\n",
    "# Load data\n",
    "cifar = torchvision.datasets.CIFAR10(\"../../data/torch/cifar\", download=True, transform=transform)\n",
    "\n",
    "# Set the training size to 80% of the total data\n",
    "train_size = int(0.8 * len(cifar))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, valid_data = torch.utils.data.random_split(cifar, [train_size, len(cifar) - train_size])\n",
    "\n",
    "# These are the classes within the dataset\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f6298",
   "metadata": {},
   "source": [
    "Get the necessary constants and define normalization for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d9b1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "normalize = transforms.Normalize(cifar_mean, cifar_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41273b69",
   "metadata": {},
   "source": [
    "### setting up the CNN\n",
    "\n",
    "\n",
    "I want to set up my CNN such that I can change the convolutions in each run, partially because that will make a difference and partially because i don't fully understand the math. I will always end with flattening and a linear layer, but I will need to change the parameters for `nn.Linear` depending on the previous convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d18d1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test if the layers are actually going to work\n",
    "\n",
    "\n",
    "# given 3x32x32\n",
    "def valid_arch(arch, input_size=(3,32,32)):\n",
    "\n",
    "    # (Cin, H, W) = input_size\n",
    "    # (Cout, _, Kh, Kw) = kernel.shape\n",
    "    # output = np.zeros((Cout, H - Kh + 1, W - Kw + 1))\n",
    "    # # next layer should be output size?\n",
    "    \n",
    "    '''\n",
    "    assert kernel shape matches (does the kernel have to fit nicely into the image?)\n",
    "    \n",
    "    prev_size = input_size\n",
    "\n",
    "    for c in conv_list:\n",
    "        \n",
    "        (Cout, _, Kh, Kw) = kernel.shape\n",
    "        next_layer = next in c\n",
    "        assert(next_layer.shape() = (Cout, H - Kh + 1, W - Kw + 1))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        # have some checker function to make sure the math is right \n",
    "\n",
    "\n",
    "        # have learning rate that works roughly ok, the pick arch, then tune learning rate and other parameters\n",
    "        # five to eight total\n",
    "\n",
    "\n",
    "\n",
    "        # sizing output should be input, in  terms of num of channels, \n",
    "        # add padding, then subtract kernel size -1, then divide by the stride size, then make sure that the output matches input\n",
    "        # can use nn.adaptiveave pool.2d, and give it 1x1 output and it'll figure it out for you\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e0b6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, arch):\n",
    "        super().__init__()\n",
    "        assert(valid_arch(arch))\n",
    "        # Dynamically create attributes for each convolution\n",
    "        self.arch = arch\n",
    "        self.depth = len(arch)\n",
    "\n",
    "        # for i in range(len(layers)):\n",
    "        #     setattr(CNN, 'l'+str(i), layers[i])\n",
    "\n",
    "\n",
    "        # self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fix linear inputs so it's dynamic\n",
    "        # if you do average pooling then after flattening the number of inputs you just put number of channels into the linear layer\n",
    "        # self.linear =  nn.Linear(32*8*8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for i in range(self.depth):\n",
    "            current = self.arch[i]\n",
    "            x = current(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd863b20",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "general strategy: find a good learning rate, then find good arch, then tune learning rate and other params\n",
    "\n",
    "\n",
    "include scheduling, but only using one. will find a good learning rate and see if i can tune it by changing the patience\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cec390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad6dae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run, \n",
    "          arch=0,\n",
    "          lr=1e-3,\n",
    "          epochs=10,\n",
    "          batch_size=64,\n",
    "          reg=1e-5,\n",
    "          device = 'mps', factor=0.1, patience=3):\n",
    "    \n",
    "    print(\"Learning rate:\", lr)\n",
    "    print(\"Factor:\", factor)\n",
    "    print(\"Patience:\", patience)\n",
    "    \n",
    "    start = time.time()\n",
    "    data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    augments = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomGrayscale(0.1),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=(0.9,1.1),\n",
    "                contrast=0,\n",
    "                saturation=0,\n",
    "                hue=0),\n",
    "            transforms.RandomCrop(\n",
    "                size=32,\n",
    "                padding=2,\n",
    "                fill=cifar_mean)\n",
    "        ])\n",
    "    \n",
    "    print(arch)\n",
    "    print(archs[arch])\n",
    "    model = CNN(archs[arch]).to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    opt = optim.SGD(model.parameters(), momentum=0.9, lr=lr, weight_decay=reg)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=factor, patience=patience)\n",
    "\n",
    "    # Naming the training runs\n",
    "    name = str(run) + '--' # Run number\n",
    "    # name += \":\".join(map(str, convolutions))\n",
    "    name += 'arch' + str(arch)\n",
    "    name += '-lr-' + str(lr) + '-bs-' + str(batch_size) + '-epochs-' + str(epochs) + '-reg-' + str(reg)\n",
    "    name += '-pat-' + str(patience) + '-fac-' + str(factor)\n",
    "    logger = tb.SummaryWriter(os.path.join(\"logs/\", name))\n",
    "    global_step = 0\n",
    "\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "\n",
    "        # Train\n",
    "\n",
    "        model.train()\n",
    "        for batch_xs, batch_ys in data_loader:\n",
    "            batch_xs = augments(batch_xs).to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "\n",
    "            preds = model(normalize(batch_xs))\n",
    "            loss_val = loss(preds, batch_ys)\n",
    "\n",
    "            logger.add_scalar('loss', loss_val, global_step=global_step)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss_val.backward()\n",
    "            opt.step()\n",
    "\n",
    "            logger.add_scalar(\"Training accuracy\", (preds.argmax(dim=1) == batch_ys).float().mean(), global_step=global_step)\n",
    "\n",
    "            global_step += 1\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        valid_accs = []\n",
    "        for batch_xs, batch_ys in valid_loader:\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            valid_preds = model(normalize(batch_xs))\n",
    "            valid_accs.append((valid_preds.argmax(dim=1) == batch_ys).float().mean())\n",
    "        valid_accuracy = torch.tensor(valid_accs).mean()\n",
    "        logger.add_scalar(\"Validation accuracy\", valid_accuracy, global_step=global_step)\n",
    "        scheduler.step(valid_accuracy)\n",
    "        print(\"Acc:\", valid_accuracy)\n",
    "        \n",
    "\n",
    "    logger.add_scalar(\"training time\", time.time() - start, global_step=global_step)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98564aa4",
   "metadata": {},
   "source": [
    "## Training and tuning\n",
    "\n",
    "\n",
    "will be a loop\n",
    "\n",
    "First, we want to make sure that we don this on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6735a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "else:\n",
    "    decive = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129485c",
   "metadata": {},
   "source": [
    "### Architectures and learning rates\n",
    "\n",
    "Trying some different learning rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0992c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up first training loop\n",
    "\n",
    "# first try some different lr\n",
    "\n",
    "archs = [torch.nn.ModuleList([\n",
    "    nn.Conv2d(3, 8, 3, padding=3), nn.ReLU(), nn.Conv2d(8, 16, 3, groups=2, padding=1, stride=2), nn.ReLU(), nn.Conv2d(16, 32, 3, stride=2), nn.Flatten(), nn.Linear(32*8*8, 10)]),\n",
    "    torch.nn.ModuleList([\n",
    "        nn.Conv2d(3, 8, (7, 7), stride=2, padding=3), nn.ReLU(), nn.Conv2d(8, 16, 3, groups=2, padding=1), nn.MaxPool2d(2, stride=2), nn.Conv2d(16, 32, 3), nn.AvgPool2d(kernel_size=(6, 6)),nn.Flatten(),nn.Linear(32, 10)\n",
    "    \n",
    "    ]),\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e8aa4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0edbf4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275ceb68ad04457790c5bd2f2c0e97ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.4553)\n",
      "Acc: tensor(0.5239)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m learning_rates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(learning_rates)):\n\u001b[0;32m----> 4\u001b[0m     cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(cnn_model\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[83], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run, arch, lr, epochs, batch_size, reg, device, factor, patience)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maugments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/autograd/profiler.py:631\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-2, 1e-1]\n",
    "\n",
    "for i in range(len(learning_rates)):\n",
    "    cnn_model = train(i, arch=0, lr=learning_rates[i])\n",
    "    torch.save(cnn_model.state_dict(), os.path.join(\"models/\", \"CNN\" + str(i) + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddffe9",
   "metadata": {},
   "source": [
    "results: it seems like in general 1e-2 had the best accuracy. after that, the accuracy plumeted about 30 percent. now i am going to tune the scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b603e",
   "metadata": {},
   "source": [
    "### Tuning the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c42e1548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba49dc37498b47228ffde9cc94afc46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.5704)\n",
      "Acc: tensor(0.5930)\n",
      "Acc: tensor(0.6009)\n",
      "Acc: tensor(0.6138)\n",
      "Acc: tensor(0.6088)\n",
      "Acc: tensor(0.6030)\n",
      "Acc: tensor(0.6145)\n",
      "Acc: tensor(0.6186)\n",
      "Acc: tensor(0.6153)\n",
      "Acc: tensor(0.6325)\n",
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000f08866e1d4ba9b9e8173923272915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.6276)\n",
      "Acc: tensor(0.6297)\n",
      "Acc: tensor(0.6338)\n",
      "Acc: tensor(0.6398)\n",
      "Acc: tensor(0.6166)\n",
      "Acc: tensor(0.6105)\n",
      "Acc: tensor(0.6437)\n",
      "Acc: tensor(0.6303)\n",
      "Acc: tensor(0.6359)\n",
      "Acc: tensor(0.6238)\n",
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6264b657907c49ecaee708b0cfb122c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.6299)\n",
      "Acc: tensor(0.6304)\n",
      "Acc: tensor(0.6283)\n",
      "Acc: tensor(0.6431)\n",
      "Acc: tensor(0.6224)\n",
      "Acc: tensor(0.6365)\n",
      "Acc: tensor(0.6352)\n",
      "Acc: tensor(0.6240)\n",
      "Acc: tensor(0.6603)\n",
      "Acc: tensor(0.6682)\n",
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4045e99c7af34d759675caa0d3d4fcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.6323)\n",
      "Acc: tensor(0.6399)\n",
      "Acc: tensor(0.6330)\n",
      "Acc: tensor(0.6334)\n",
      "Acc: tensor(0.6377)\n",
      "Acc: tensor(0.6640)\n",
      "Acc: tensor(0.6688)\n",
      "Acc: tensor(0.6700)\n",
      "Acc: tensor(0.6711)\n",
      "Acc: tensor(0.6719)\n",
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2b09df65fc432594df3f1ea5452a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.6320)\n",
      "Acc: tensor(0.6197)\n",
      "Acc: tensor(0.6464)\n",
      "Acc: tensor(0.6307)\n",
      "Acc: tensor(0.6470)\n",
      "Acc: tensor(0.6300)\n",
      "Acc: tensor(0.6282)\n",
      "Acc: tensor(0.6668)\n",
      "Acc: tensor(0.6721)\n",
      "Acc: tensor(0.6724)\n"
     ]
    }
   ],
   "source": [
    "patience = [5,4,3,2,1]\n",
    "\n",
    "for i in range(len(patience)):\n",
    "    cnn_model = train(i, arch=0, lr=1e-2, patience=patience[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a89f2",
   "metadata": {},
   "source": [
    "patience = 1 was best, but not by that much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35542330",
   "metadata": {},
   "source": [
    "now doing the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56fb4557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 1\n",
      "0\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2)\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  (6): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fb028f3b014594ae95b2b87835a0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[91], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(run, arch, lr, epochs, batch_size, reg, device, factor, patience)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maugments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl-class/lib/python3.11/site-packages/PIL/Image.py:3118\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3118\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3120\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_model = train(i, arch=0, lr=1e-2, patience=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12ab21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Factor: 0.1\n",
      "Patience: 1\n",
      "1\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (5): AvgPool2d(kernel_size=(6, 6), stride=(6, 6), padding=0)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887e81a3ee0a487e98da1015c66b7e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.3739)\n",
      "Acc: tensor(0.4291)\n",
      "Acc: tensor(0.4200)\n",
      "Acc: tensor(0.4708)\n",
      "Acc: tensor(0.4492)\n",
      "Acc: tensor(0.4811)\n",
      "Acc: tensor(0.4868)\n",
      "Acc: tensor(0.5079)\n",
      "Acc: tensor(0.4984)\n",
      "Acc: tensor(0.5119)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnn_model = train(i, arch=1, lr=1e-2, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699d61d",
   "metadata": {},
   "source": [
    "results from arch\n",
    "arch 0 was better\n",
    "arch 1 not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef587e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize for fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
